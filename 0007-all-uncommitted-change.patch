From 3be77c1e2e0b81cf1b75479763194bf98e597cd1 Mon Sep 17 00:00:00 2001
From: Harshad Shirwadkar <harshads@google.com>
Date: Wed, 8 Jun 2022 02:02:11 +0000
Subject: [PATCH 7/7] all uncommitted change

---
 fs/ext4/ext4.h              |   6 +
 fs/ext4/ext4_jbd2.h         |   8 +-
 fs/ext4/extents_status.c    |   5 +-
 fs/ext4/fast_commit.c       | 224 ++++++++++++++++++++++++++++--------
 fs/ext4/fast_commit.h       |  16 +++
 fs/ext4/inode.c             |  20 +++-
 fs/ext4/super.c             |   1 +
 fs/jbd2/commit.c            |  31 +++--
 fs/jbd2/journal.c           |  61 +++++++---
 fs/jbd2/transaction.c       |  22 ++++
 include/linux/jbd2.h        |  20 +++-
 include/trace/events/jbd2.h |   2 +-
 12 files changed, 330 insertions(+), 86 deletions(-)

diff --git a/fs/ext4/ext4.h b/fs/ext4/ext4.h
index 3d6f2537a877..2a1ad9838f2f 100644
--- a/fs/ext4/ext4.h
+++ b/fs/ext4/ext4.h
@@ -715,6 +715,7 @@ enum {
 #define EXT4_GET_BLOCKS_IO_SUBMIT		0x0400
 	/* Caller is in the atomic contex, find extent if it has been cached */
 #define EXT4_GET_BLOCKS_CACHED_NOWAIT		0x0800
+#define EXT4_GET_BLOCKS_NOLOCK			0x1000
 
 /*
  * The bit position of these flags must not overlap with any of the
@@ -1743,6 +1744,10 @@ struct ext4_sb_info {
 	 * following fields:
 	 * ei->i_fc_list, s_fc_dentry_q, s_fc_q, s_fc_bytes, s_fc_bh.
 	 */
+	int fc_flush_required;
+	struct ext4_fsync_hist {
+		int count;
+	} *s_fsync_hist;
 	spinlock_t s_fc_lock;
 	struct buffer_head *s_fc_bh;
 	struct ext4_fc_stats s_fc_stats;
@@ -2899,6 +2904,7 @@ void ext4_fc_del(struct inode *inode);
 bool ext4_fc_replay_check_excluded(struct super_block *sb, ext4_fsblk_t block);
 void ext4_fc_replay_cleanup(struct super_block *sb);
 int ext4_fc_commit(journal_t *journal, tid_t commit_tid);
+void ext4_fc_mark_needs_flush(struct super_block *sb);
 int __init ext4_fc_init_dentry_cache(void);
 void ext4_fc_destroy_dentry_cache(void);
 int ext4_fc_record_regions(struct super_block *sb, int ino,
diff --git a/fs/ext4/ext4_jbd2.h b/fs/ext4/ext4_jbd2.h
index 0c77697d5e90..ead7503ef19c 100644
--- a/fs/ext4/ext4_jbd2.h
+++ b/fs/ext4/ext4_jbd2.h
@@ -420,18 +420,22 @@ static inline int ext4_journal_force_commit(journal_t *journal)
 static inline int ext4_jbd2_inode_add_write(handle_t *handle,
 		struct inode *inode, loff_t start_byte, loff_t length)
 {
-	if (ext4_handle_valid(handle))
+	if (ext4_handle_valid(handle)) {
+		ext4_fc_mark_needs_flush(inode->i_sb);
 		return jbd2_journal_inode_ranged_write(handle,
 				EXT4_I(inode)->jinode, start_byte, length);
+	}
 	return 0;
 }
 
 static inline int ext4_jbd2_inode_add_wait(handle_t *handle,
 		struct inode *inode, loff_t start_byte, loff_t length)
 {
-	if (ext4_handle_valid(handle))
+	if (ext4_handle_valid(handle)) {
+		ext4_fc_mark_needs_flush(inode->i_sb);
 		return jbd2_journal_inode_ranged_wait(handle,
 				EXT4_I(inode)->jinode, start_byte, length);
+	}
 	return 0;
 }
 
diff --git a/fs/ext4/extents_status.c b/fs/ext4/extents_status.c
index 4a00e2f019d9..a93be2e1f6ad 100644
--- a/fs/ext4/extents_status.c
+++ b/fs/ext4/extents_status.c
@@ -1575,6 +1575,8 @@ static int __es_shrink(struct ext4_sb_info *sbi, int nr_to_scan,
 			continue;
 		}
 
+		ext4_fc_commit(sbi->s_journal, ei->i_sync_tid);
+
 		if (ei == locked_ei || !write_trylock(&ei->i_es_lock)) {
 			nr_skipped++;
 			continue;
@@ -1648,7 +1650,8 @@ static unsigned long ext4_es_scan(struct shrinker *shrink,
 	ret = percpu_counter_read_positive(&sbi->s_es_stats.es_stats_shk_cnt);
 	trace_ext4_es_shrink_scan_enter(sbi->s_sb, nr_to_scan, ret);
 
-	nr_shrunk = __es_shrink(sbi, nr_to_scan, NULL);
+	//nr_shrunk = __es_shrink(sbi, nr_to_scan, NULL);
+	nr_shrunk = 0;
 
 	ret = percpu_counter_read_positive(&sbi->s_es_stats.es_stats_shk_cnt);
 	trace_ext4_es_shrink_scan_exit(sbi->s_sb, nr_shrunk, ret);
diff --git a/fs/ext4/fast_commit.c b/fs/ext4/fast_commit.c
index 269dfc4d6781..890527b0d9f1 100644
--- a/fs/ext4/fast_commit.c
+++ b/fs/ext4/fast_commit.c
@@ -10,6 +10,7 @@
 #include "ext4.h"
 #include "ext4_jbd2.h"
 #include "ext4_extents.h"
+#include "extents_status.h"
 #include "mballoc.h"
 
 /*
@@ -176,6 +177,14 @@
  *    status tree. This would get rid of the need to call ext4_fc_track_inode()
  *    before acquiring i_data_sem. To do that we would need to ensure that
  *    modified extents from the extent status tree are not evicted from memory.
+
+dev=vdb; dmesg -c > /dev/null; mkfs.ext4 -O fast_commit /dev/$dev; mount /dev/$dev /mnt; echo t > /mnt/t; time sync /mnt/t; dmesg -c; cat /proc/fs/jbd2/${dev}-8/info ; umount /mnt
+dev=vdb; dmesg -c > /dev/null; mkfs.ext4 /dev/$dev; mount /dev/$dev /mnt; echo t > /mnt/t; time sync /mnt/t; time sync /mnt/t; time sync /mnt/t; dmesg -c; cat /proc/fs/jbd2/${dev}-8/info ;  cat /proc/fs/ext4/${dev}/fc_info; umount /mnt
+dev=nvme0n1p1; dmesg -c > /dev/null; mkfs.ext4 /dev/$dev; mount /dev/$dev /mnt; echo t > /mnt/t; time sync /mnt/t; dmesg -c; cat /proc/fs/jbd2/${dev}-8/info ; umount /mnt
+dev=nvme0n1p1; dmesg -c > /dev/null; mkfs.ext4 -O fast_commit /dev/$dev; mount /dev/$dev /mnt; touch /mnt/m; sync; echo t > /mnt/t; time sync /mnt/t; dmesg -c; cat /proc/fs/ext4/nvme0n1p1/fc_info ; umount /mnt
+dev=vdb; dmesg -c > /dev/null; mkfs.ext4 /dev/$dev; mount /dev/$dev  -O journal_async_commit /mnt; echo t > /mnt/t; time sync /mnt/t; time sync /mnt/t; time sync /mnt/t; dmesg -c; cat /proc/fs/jbd2/${dev}-8/info ;  umount /mnt
+
+
  */
 
 #include <trace/events/ext4.h>
@@ -533,6 +542,8 @@ static int __track_inode(struct inode *inode, void *arg, bool update)
 }
 
 void ext4_fc_track_inode(handle_t *handle, struct inode *inode)
+__acquires(fc_committing_lock)
+__releases(fc_committing_lock)
 {
 	struct ext4_inode_info *ei = EXT4_I(inode);
 	wait_queue_head_t *wq;
@@ -555,17 +566,17 @@ void ext4_fc_track_inode(handle_t *handle, struct inode *inode)
 
 	if (!test_opt2(inode->i_sb, JOURNAL_FAST_COMMIT) ||
 	    (EXT4_SB(inode->i_sb)->s_mount_state & EXT4_FC_REPLAY) ||
-		ext4_test_mount_flag(inode->i_sb, EXT4_MF_FC_INELIGIBLE) ||
-		!list_empty(&ei->i_fc_list))
+	    ext4_test_mount_flag(inode->i_sb, EXT4_MF_FC_INELIGIBLE))
 		return;
 
 	/*
 	 * If we come here, we may sleep while waiting for the inode to
-	 * commit. We shouldn't be holding i_data_sem in write mode when we go
-	 * to sleep since the commit path needs to grab the lock while
-	 * committing the inode.
+	 * commit. We shouldn't be holding i_data_sem when we go to sleep since
+	 * the commit path needs to grab the lock while committing the inode.
 	 */
-	WARN_ON(lockdep_is_held_type(&ei->i_data_sem, 1));
+#ifdef CONFIG_LOCKDEP
+	// WARN_ON(lockdep_is_held(&ei->i_data_sem));
+#endif
 
 	while (ext4_test_inode_state(inode, EXT4_STATE_FC_COMMITTING)) {
 #if (BITS_PER_LONG < 64)
@@ -642,19 +653,42 @@ void ext4_fc_track_range(handle_t *handle, struct inode *inode, ext4_lblk_t star
 	trace_ext4_fc_track_range(handle, inode, start, end, ret);
 }
 
-static void ext4_fc_submit_bh(struct super_block *sb, bool is_tail)
+static void ext4_fc_submit_bh(struct super_block *sb, bool is_tail, bool needs_flush)
 {
 	blk_opf_t write_flags = REQ_SYNC;
 	struct buffer_head *bh = EXT4_SB(sb)->s_fc_bh;
+	static int fua_ineligible = 0;
+ 
+	if (!is_tail) {
+		// non-tail
+		fua_ineligible = 1;
+	} else {
+		// tail
+		if (fua_ineligible == 1) {
+			// dont do fua
+			if (test_opt(sb, BARRIER))
+				write_flags |= REQ_PREFLUSH;
+		} else {
+			// do fua
+			if (test_opt(sb, BARRIER))
+				write_flags |= REQ_FUA;
+			if (needs_flush)
+				write_flags |= REQ_PREFLUSH;
+		}
+		fua_ineligible = 0;
+	}
 
 	/* Add REQ_FUA | REQ_PREFLUSH only its tail */
-	if (test_opt(sb, BARRIER) && is_tail)
-		write_flags |= REQ_FUA | REQ_PREFLUSH;
+	// if (test_opt(sb, BARRIER) && is_tail)
+	// 	write_flags |= REQ_FUA | REQ_PREFLUSH;
 	lock_buffer(bh);
 	set_buffer_dirty(bh);
 	set_buffer_uptodate(bh);
 	bh->b_end_io = ext4_end_buffer_io_sync;
 	submit_bh(REQ_OP_WRITE | write_flags, bh);
+	EXT4_SB(sb)->s_fc_stats.real_numblks++;
+	if (write_flags & REQ_PREFLUSH)
+		EXT4_SB(sb)->s_fc_stats.num_flushes++;
 	EXT4_SB(sb)->s_fc_bh = NULL;
 }
 
@@ -717,7 +751,7 @@ static u8 *ext4_fc_reserve_space(struct super_block *sb, int len, u32 *crc)
 	memset(dst + EXT4_FC_TAG_BASE_LEN, 0, remaining);
 	*crc = ext4_chksum(sbi, *crc, sbi->s_fc_bh->b_data, bsize);
 
-	ext4_fc_submit_bh(sb, false);
+	ext4_fc_submit_bh(sb, false, false);
 
 	ret = jbd2_fc_get_buf(EXT4_SB(sb)->s_journal, &bh);
 	if (ret)
@@ -735,7 +769,7 @@ static u8 *ext4_fc_reserve_space(struct super_block *sb, int len, u32 *crc)
  * in the block, next commit shouldn't use it. That's why tail tag
  * has the length as that of the remaining space on the block.
  */
-static int ext4_fc_write_tail(struct super_block *sb, u32 crc)
+static int ext4_fc_write_tail(struct super_block *sb, u32 crc, int needs_flush)
 {
 	struct ext4_sb_info *sbi = EXT4_SB(sb);
 	struct ext4_fc_tl tl;
@@ -769,7 +803,7 @@ static int ext4_fc_write_tail(struct super_block *sb, u32 crc)
 	dst += sizeof(tail.fc_crc);
 	memset(dst, 0, bsize - off); /* Don't leak uninitialized memory. */
 
-	ext4_fc_submit_bh(sb, true);
+	ext4_fc_submit_bh(sb, true, needs_flush);
 
 	return 0;
 }
@@ -823,6 +857,11 @@ static bool ext4_fc_add_dentry_tlv(struct super_block *sb, u32 *crc,
 	return true;
 }
 
+void ext4_fc_mark_needs_flush(struct super_block *sb)
+{
+	EXT4_SB(sb)->fc_flush_required = 1;
+}
+
 /*
  * Writes inode in the fast commit space under TLV with tag @tag.
  * Returns 0 on success, error on failure.
@@ -898,7 +937,7 @@ static int ext4_fc_write_inode_data(struct inode *inode, u32 *crc)
 	while (cur_lblk_off <= new_blk_size) {
 		map.m_lblk = cur_lblk_off;
 		map.m_len = new_blk_size - cur_lblk_off + 1;
-		ret = ext4_map_blocks(NULL, inode, &map, 0);
+		ret = ext4_map_blocks(NULL, inode, &map, EXT4_GET_BLOCKS_NOLOCK);
 		if (ret < 0)
 			return -ECANCELED;
 
@@ -989,7 +1028,7 @@ static int ext4_fc_wait_inode_data_all(journal_t *journal)
 }
 
 /* Commit all the directory entry updates */
-static int ext4_fc_commit_dentry_updates(journal_t *journal, u32 *crc)
+static int ext4_fc_commit_dentry_updates(journal_t *journal, u32 *crc, int *work_done)
 __acquires(&sbi->s_fc_lock)
 __releases(&sbi->s_fc_lock)
 {
@@ -1004,6 +1043,7 @@ __releases(&sbi->s_fc_lock)
 		return 0;
 	list_for_each_entry_safe(fc_dentry, fc_dentry_n,
 				 &sbi->s_fc_dentry_q[FC_Q_MAIN], fcd_list) {
+		*work_done = 1;
 		if (fc_dentry->fcd_op != EXT4_FC_TAG_CREAT) {
 			spin_unlock(&sbi->s_fc_lock);
 			if (!ext4_fc_add_dentry_tlv(sb, crc, fc_dentry)) {
@@ -1017,7 +1057,9 @@ __releases(&sbi->s_fc_lock)
 		 * With fcd_dilist we need not loop in sbi->s_fc_q to get the
 		 * corresponding inode pointer
 		 */
-		WARN_ON(list_empty(&fc_dentry->fcd_dilist));
+		// WARN_ON(list_empty(&fc_dentry->fcd_dilist));
+		// if (list_empty(&fc_dentry->fcd_dilist))
+		// 	continue;
 		ei = list_first_entry(&fc_dentry->fcd_dilist,
 				struct ext4_inode_info, i_fc_dilist);
 		inode = &ei->vfs_inode;
@@ -1053,7 +1095,9 @@ __releases(&sbi->s_fc_lock)
 	return ret;
 }
 
-static int ext4_fc_perform_commit(journal_t *journal)
+static int ext4_fc_perform_commit(journal_t *journal, int *work_done, int *flush)
+__acquires(fc_committing_lock)
+__releases(fc_committing_lock)
 {
 	struct super_block *sb = journal->j_private;
 	struct ext4_sb_info *sbi = EXT4_SB(sb);
@@ -1063,30 +1107,39 @@ static int ext4_fc_perform_commit(journal_t *journal)
 	struct blk_plug plug;
 	int ret = 0;
 	u32 crc = 0;
+	ktime_t prev = ktime_get();
 
 	/* Lock the journal */
-	jbd2_journal_lock_updates(journal);
+	jbd2_journal_lock_updates_no_rsv(journal);
+	sbi->s_fc_stats.lock_updates_time += get_us_since(&prev);
+
 	spin_lock(&sbi->s_fc_lock);
 	list_for_each_entry(iter, &sbi->s_fc_q[FC_Q_MAIN], i_fc_list) {
 		ext4_set_inode_state(&iter->vfs_inode,
 				     EXT4_STATE_FC_COMMITTING);
 	}
 	spin_unlock(&sbi->s_fc_lock);
+	*flush = sbi->fc_flush_required;
+	sbi->fc_flush_required = 0;
 	jbd2_journal_unlock_updates(journal);
+	sbi->s_fc_stats.mark_inodes_committing += get_us_since(&prev);
 
-	ret = ext4_fc_submit_inode_data_all(journal);
-	if (ret)
-		return ret;
+	if (*flush) {
+		ret = ext4_fc_submit_inode_data_all(journal);
+		if (ret)
+			return ret;
 
-	ret = ext4_fc_wait_inode_data_all(journal);
-	if (ret)
-		return ret;
+		ret = ext4_fc_wait_inode_data_all(journal);
+		if (ret)
+			return ret;
+	}
 
+	sbi->s_fc_stats.flush_data_time += get_us_since(&prev);
 	/*
 	 * If file system device is different from journal device, issue a cache
 	 * flush before we start writing fast commit blocks.
 	 */
-	if (journal->j_fs_dev != journal->j_dev)
+	if (*flush && journal->j_fs_dev != journal->j_dev)
 		blkdev_issue_flush(journal->j_fs_dev);
 
 	blk_start_plug(&plug);
@@ -1106,17 +1159,17 @@ static int ext4_fc_perform_commit(journal_t *journal)
 	}
 
 	spin_lock(&sbi->s_fc_lock);
-	ret = ext4_fc_commit_dentry_updates(journal, &crc);
+	ret = ext4_fc_commit_dentry_updates(journal, &crc, work_done);
 	if (ret) {
 		spin_unlock(&sbi->s_fc_lock);
 		goto out;
 	}
-
+	sbi->s_fc_stats.dentry_commit_time += get_us_since(&prev);
 	list_for_each_entry(iter, &sbi->s_fc_q[FC_Q_MAIN], i_fc_list) {
 		inode = &iter->vfs_inode;
 		if (!ext4_test_inode_state(inode, EXT4_STATE_FC_COMMITTING))
 			continue;
-
+		*work_done = 1;
 		spin_unlock(&sbi->s_fc_lock);
 		ret = ext4_fc_write_inode_data(inode, &crc);
 		if (ret)
@@ -1124,6 +1177,9 @@ static int ext4_fc_perform_commit(journal_t *journal)
 		ret = ext4_fc_write_inode(inode, &crc);
 		if (ret)
 			goto out;
+		spin_lock(&sbi->s_fc_lock);
+	}
+	list_for_each_entry(iter, &sbi->s_fc_q[FC_Q_MAIN], i_fc_list) {
 		ext4_clear_inode_state(inode, EXT4_STATE_FC_COMMITTING);
 		/*
 		 * Make sure clearing of EXT4_STATE_FC_COMMITTING is
@@ -1136,27 +1192,42 @@ static int ext4_fc_perform_commit(journal_t *journal)
 #else
 		wake_up_bit(&iter->i_flags, EXT4_STATE_FC_COMMITTING);
 #endif
-		spin_lock(&sbi->s_fc_lock);
 	}
 	spin_unlock(&sbi->s_fc_lock);
+	sbi->s_fc_stats.write_inodes_time += get_us_since(&prev);
 
-	ret = ext4_fc_write_tail(sb, crc);
+	if (*work_done)
+		ret = ext4_fc_write_tail(sb, crc, *flush);
+	else {
+		sbi->s_fc_stats.empty_commits++;
+		ret = 0;
+	}
 
 out:
 	blk_finish_plug(&plug);
+	sbi->s_fc_stats.tail_write_time += get_us_since(&prev);
 	return ret;
 }
 
 static void ext4_fc_update_stats(struct super_block *sb, int status,
-				 u64 commit_time, int nblks, tid_t commit_tid)
+				 u64 commit_time, int nblks, int flush, tid_t commit_tid)
 {
 	struct ext4_fc_stats *stats = &EXT4_SB(sb)->s_fc_stats;
 
 	ext4_debug("Fast commit ended with status = %d for tid %u",
 			status, commit_tid);
+	if (nblks == 1) {
+		if (flush)
+			stats->single_block_flush++;
+		else
+			stats->single_block_fua++;
+	} else if (nblks > 1) {
+		stats->multiblock++;
+	}
 	if (status == EXT4_FC_STATUS_OK) {
 		stats->fc_num_commits++;
 		stats->fc_numblks += nblks;
+		stats->total_commit_time += commit_time / 1000;
 		if (likely(stats->s_fc_avg_commit_time))
 			stats->s_fc_avg_commit_time =
 				(commit_time +
@@ -1180,14 +1251,16 @@ static void ext4_fc_update_stats(struct super_block *sb, int status,
  * due to various reasons, we fall back to full commit. Returns 0
  * on success, error otherwise.
  */
-int ext4_fc_commit(journal_t *journal, tid_t commit_tid)
+int __ext4_fc_commit(journal_t *journal, tid_t commit_tid)
 {
 	struct super_block *sb = journal->j_private;
 	struct ext4_sb_info *sbi = EXT4_SB(sb);
 	int nblks = 0, ret, bsize = journal->j_blocksize;
 	int subtid = atomic_read(&sbi->s_fc_subtid);
 	int status = EXT4_FC_STATUS_OK, fc_bufs_before = 0;
-	ktime_t start_time, commit_time;
+	ktime_t start_time, prev, commit_time;
+	int old_ioprio;
+	int work_done, flush;
 
 	if (!test_opt2(sb, JOURNAL_FAST_COMMIT))
 		return jbd2_complete_transaction(journal, commit_tid);
@@ -1195,6 +1268,7 @@ int ext4_fc_commit(journal_t *journal, tid_t commit_tid)
 	trace_ext4_fc_commit_start(sb, commit_tid);
 
 	start_time = ktime_get();
+	prev = start_time;
 
 restart_fc:
 	ret = jbd2_fc_begin_commit(journal, commit_tid);
@@ -1203,15 +1277,17 @@ int ext4_fc_commit(journal_t *journal, tid_t commit_tid)
 		if (atomic_read(&sbi->s_fc_subtid) <= subtid &&
 			commit_tid > journal->j_commit_sequence)
 			goto restart_fc;
-		ext4_fc_update_stats(sb, EXT4_FC_STATUS_SKIPPED, 0, 0,
+		ext4_fc_update_stats(sb, EXT4_FC_STATUS_SKIPPED, 0, 0, 0,
 				commit_tid);
 		return 0;
-	} else if (ret) {
+	}
+	sbi->s_fc_stats.begin_time += get_us_since(&prev);
+	if (ret) {
 		/*
 		 * Commit couldn't start. Just update stats and perform a
 		 * full commit.
 		 */
-		ext4_fc_update_stats(sb, EXT4_FC_STATUS_FAILED, 0, 0,
+		ext4_fc_update_stats(sb, EXT4_FC_STATUS_FAILED, 0, 0, 0,
 				commit_tid);
 		return jbd2_complete_transaction(journal, commit_tid);
 	}
@@ -1224,32 +1300,58 @@ int ext4_fc_commit(journal_t *journal, tid_t commit_tid)
 		status = EXT4_FC_STATUS_INELIGIBLE;
 		goto fallback;
 	}
-
+	old_ioprio = get_current_ioprio();
+	set_task_ioprio(current, IOPRIO_PRIO_VALUE(IOPRIO_CLASS_BE, 3));
 	fc_bufs_before = (sbi->s_fc_bytes + bsize - 1) / bsize;
-	ret = ext4_fc_perform_commit(journal);
+	ret = ext4_fc_perform_commit(journal, &work_done, &flush);
 	if (ret < 0) {
 		status = EXT4_FC_STATUS_FAILED;
 		goto fallback;
 	}
+	sbi->s_fc_stats.perform_time += get_us_since(&prev);
 	nblks = (sbi->s_fc_bytes + bsize - 1) / bsize - fc_bufs_before;
-	ret = jbd2_fc_wait_bufs(journal, nblks);
-	if (ret < 0) {
-		status = EXT4_FC_STATUS_FAILED;
-		goto fallback;
+
+	if (work_done) {
+		ret = jbd2_fc_wait_bufs(journal, nblks);
+		if (ret < 0) {
+			status = EXT4_FC_STATUS_FAILED;
+			goto fallback;
+		}
+	} else {
+		ret = 0;
 	}
+	sbi->s_fc_stats.wait_bufs_time += get_us_since(&prev);
 	atomic_inc(&sbi->s_fc_subtid);
 	ret = jbd2_fc_end_commit(journal);
+	set_task_ioprio(current, old_ioprio);
 	/*
 	 * weight the commit time higher than the average time so we
 	 * don't react too strongly to vast changes in the commit time
 	 */
 	commit_time = ktime_to_ns(ktime_sub(ktime_get(), start_time));
-	ext4_fc_update_stats(sb, status, commit_time, nblks, commit_tid);
+	ext4_fc_update_stats(sb, status, commit_time, nblks, flush, commit_tid);
 	return ret;
 
 fallback:
+	set_task_ioprio(current, old_ioprio);
 	ret = jbd2_fc_end_commit_fallback(journal);
-	ext4_fc_update_stats(sb, status, 0, 0, commit_tid);
+	ext4_fc_update_stats(sb, status, 0, 0, 0, commit_tid);
+	return ret;
+}
+
+
+
+int ext4_fc_commit(journal_t *journal, tid_t commit_tid)
+{
+	int ret, fsync_latency;
+	struct ext4_sb_info *sbi = EXT4_SB(journal->j_private);
+
+	ktime_t start_time = ktime_get();
+	ret = __ext4_fc_commit(journal, commit_tid);
+	fsync_latency = ktime_to_us(ktime_sub(ktime_get(), start_time));
+	if (fsync_latency >= 50000)
+		fsync_latency = 49999;
+	sbi->s_fsync_hist[fsync_latency].count++;
 	return ret;
 }
 
@@ -2272,15 +2374,41 @@ int ext4_fc_info_show(struct seq_file *seq, void *v)
 	if (v != SEQ_START_TOKEN)
 		return 0;
 
-	seq_printf(seq,
-		"fc stats:\n%ld commits\n%ld ineligible\n%ld numblks\n%lluus avg_commit_time\n",
-		   stats->fc_num_commits, stats->fc_ineligible_commits,
-		   stats->fc_numblks,
-		   div_u64(stats->s_fc_avg_commit_time, 1000));
+	seq_printf(seq, "fc stats:\n");
+	seq_printf(seq, "%ld commits (%ld skipped):\n", stats->fc_num_commits, stats->fc_skipped_commits);
+	seq_printf(seq, "\t%ld ineligible\n", stats->fc_ineligible_commits);
+	seq_printf(seq, "\t%ld failed\n", stats->fc_failed_commits);
+	seq_printf(seq, "\t%ld empty\n", stats->empty_commits);
+	seq_printf(seq, "Commit type breakdown:\n");
+	seq_printf(seq, "\t%ld fua\n", stats->single_block_fua);
+	seq_printf(seq, "\t%ld fua+preflush\n", stats->single_block_flush);
+	seq_printf(seq, "\t%ld multiblock\n", stats->multiblock);
+	seq_printf(seq, "%ld numblks\n", stats->fc_numblks);
+	seq_printf(seq, "%ld real_numblks\n", stats->real_numblks);
+	seq_printf(seq, "%ld flushes\n", stats->num_flushes);
+	seq_printf(seq, "%lld avg_commit_time\n", div_u64(stats->s_fc_avg_commit_time, 1000));
+	seq_printf(seq, "time breakdown:\n");
+	seq_printf(seq, "\ttotal: %lld\n", stats->total_commit_time);
+	seq_printf(seq, "\tbegin_time: %lld\n", stats->begin_time);
+	seq_printf(seq, "\tperform_time: %lld\n", stats->perform_time);
+	seq_printf(seq, "\t\tlock_updates_time: %lld\n", stats->lock_updates_time);
+	seq_printf(seq, "\t\tmark_inodes_committing: %lld\n", stats->mark_inodes_committing);
+	seq_printf(seq, "\t\tflush_data_time: %lld\n", stats->flush_data_time);
+	seq_printf(seq, "\t\tdentry_commit_time: %lld\n", stats->dentry_commit_time);
+	seq_printf(seq, "\t\twrite_inodes_time: %lld\n", stats->write_inodes_time);
+	seq_printf(seq, "\t\ttail_write_time: %lld\n", stats->tail_write_time);
+	seq_printf(seq, "\twait_bufs_time: %lld\n", stats->wait_bufs_time);
+
+
 	seq_puts(seq, "Ineligible reasons:\n");
 	for (i = 0; i < EXT4_FC_REASON_MAX; i++)
 		seq_printf(seq, "\"%s\":\t%d\n", fc_ineligible_reasons[i],
 			stats->fc_ineligible_reason_count[i]);
+	seq_puts(seq, "fsync: \n");
+	for (i = 0; i < 50000; i++) {
+		if (sbi->s_fsync_hist[i].count != 0)
+			seq_printf(seq, "%d,%d\n", i, sbi->s_fsync_hist[i].count);
+	}
 
 	return 0;
 }
diff --git a/fs/ext4/fast_commit.h b/fs/ext4/fast_commit.h
index 2fadb2c4780c..2f9c9c7a6ddb 100644
--- a/fs/ext4/fast_commit.h
+++ b/fs/ext4/fast_commit.h
@@ -122,7 +122,23 @@ struct ext4_fc_stats {
 	unsigned long fc_failed_commits;
 	unsigned long fc_skipped_commits;
 	unsigned long fc_numblks;
+	unsigned long real_numblks;
+	unsigned long num_flushes;
+	unsigned long empty_commits;
+	unsigned long single_block_fua;
+	unsigned long single_block_flush;
+	unsigned long multiblock;
 	u64 s_fc_avg_commit_time;
+	u64 lock_updates_time;
+	u64 mark_inodes_committing;
+	u64 flush_data_time;
+	u64 dentry_commit_time;
+	u64 write_inodes_time;
+	u64 tail_write_time;
+	u64 total_commit_time;
+	u64 perform_time;
+	u64 begin_time;
+	u64 wait_bufs_time;
 };
 
 #define EXT4_FC_REPLAY_REALLOC_INCREMENT	4
diff --git a/fs/ext4/inode.c b/fs/ext4/inode.c
index c9c975a99b47..2e26e21b9b19 100644
--- a/fs/ext4/inode.c
+++ b/fs/ext4/inode.c
@@ -543,7 +543,8 @@ int ext4_map_blocks(handle_t *handle, struct inode *inode,
 	 * Try to see if we can get the block without requesting a new
 	 * file system block.
 	 */
-	down_read(&EXT4_I(inode)->i_data_sem);
+	if (!(flags & EXT4_GET_BLOCKS_NOLOCK))
+		down_read(&EXT4_I(inode)->i_data_sem);
 	if (ext4_test_inode_flag(inode, EXT4_INODE_EXTENTS)) {
 		retval = ext4_ext_map_blocks(handle, inode, map, 0);
 	} else {
@@ -570,7 +571,8 @@ int ext4_map_blocks(handle_t *handle, struct inode *inode,
 		ext4_es_insert_extent(inode, map->m_lblk, map->m_len,
 				      map->m_pblk, status);
 	}
-	up_read((&EXT4_I(inode)->i_data_sem));
+	if (!(flags & EXT4_GET_BLOCKS_NOLOCK))
+		up_read((&EXT4_I(inode)->i_data_sem));
 
 found:
 	if (retval > 0 && map->m_flags & EXT4_MAP_MAPPED) {
@@ -612,6 +614,7 @@ int ext4_map_blocks(handle_t *handle, struct inode *inode,
 	 * the write lock of i_data_sem, and call get_block()
 	 * with create == 1 flag.
 	 */
+	WARN_ON((flags & EXT4_GET_BLOCKS_NOLOCK) != 0);
 	down_write(&EXT4_I(inode)->i_data_sem);
 
 	/*
@@ -5446,11 +5449,17 @@ int ext4_setattr(struct mnt_idmap *idmap, struct dentry *dentry,
 					(attr->ia_size > 0 ? attr->ia_size - 1 : 0) >>
 					inode->i_sb->s_blocksize_bits);
 
+			/*
+			 * Since we are going to call ext4_mark_inode_dirty with
+			 * i_data_sem held, explicitly call ext4_fc_track_inode
+			 * first.
+			 */
+			ext4_fc_track_inode(handle, inode);
+			down_write(&EXT4_I(inode)->i_data_sem);
+			EXT4_I(inode)->i_disksize = attr->ia_size;
 			rc = ext4_mark_inode_dirty(handle, inode);
 			if (!error)
 				error = rc;
-			down_write(&EXT4_I(inode)->i_data_sem);
-			EXT4_I(inode)->i_disksize = attr->ia_size;
 
 			/*
 			 * We have to update i_size under i_data_sem together
@@ -5769,6 +5778,9 @@ ext4_reserve_inode_write(handle_t *handle, struct inode *inode,
 		ext4_fc_track_inode(handle, inode);
 	}
 	ext4_std_error(inode->i_sb, err);
+	if (err)
+		ext4_fc_mark_ineligible(inode->i_sb, EXT4_FC_REASON_NOMEM, handle);
+
 	return err;
 }
 
diff --git a/fs/ext4/super.c b/fs/ext4/super.c
index 3c585295c71b..353c165adcef 100644
--- a/fs/ext4/super.c
+++ b/fs/ext4/super.c
@@ -4477,6 +4477,7 @@ static void ext4_fast_commit_init(struct super_block *sb)
 	ext4_clear_mount_flag(sb, EXT4_MF_FC_INELIGIBLE);
 	sbi->s_fc_ineligible_tid = 0;
 	spin_lock_init(&sbi->s_fc_lock);
+	sbi->s_fsync_hist = kzalloc(sizeof(struct ext4_fsync_hist) * 50000, GFP_KERNEL);
 	memset(&sbi->s_fc_stats, 0, sizeof(sbi->s_fc_stats));
 	sbi->s_fc_replay_state.fc_regions = NULL;
 	sbi->s_fc_replay_state.fc_regions_size = 0;
diff --git a/fs/jbd2/commit.c b/fs/jbd2/commit.c
index 5e122586e06e..2559745680e0 100644
--- a/fs/jbd2/commit.c
+++ b/fs/jbd2/commit.c
@@ -26,6 +26,9 @@
 #include <linux/bitops.h>
 #include <trace/events/jbd2.h>
 
+
+// ktime_t jthread_wakes_up;
+// ktime_t commit_done;
 /*
  * IO end handler for temporary buffer_heads handling writes to the journal.
  */
@@ -375,7 +378,9 @@ void jbd2_journal_commit_transaction(journal_t *journal)
 	int csum_size = 0;
 	LIST_HEAD(io_bufs);
 	LIST_HEAD(log_bufs);
+	ktime_t prev;
 
+	prev = ktime_get();
 	if (jbd2_journal_has_csum_v2or3(journal))
 		csum_size = sizeof(struct jbd2_journal_block_tail);
 
@@ -445,8 +450,7 @@ void jbd2_journal_commit_transaction(journal_t *journal)
 	stats.run.rs_locked = jiffies;
 	if (commit_transaction->t_requested)
 		stats.run.rs_request_delay =
-			jbd2_time_diff(commit_transaction->t_requested,
-				       stats.run.rs_locked);
+			ktime_to_us(ktime_sub(ktime_get(), commit_transaction->t_requested));
 	stats.run.rs_running = jbd2_time_diff(commit_transaction->t_start,
 					      stats.run.rs_locked);
 
@@ -525,9 +529,7 @@ void jbd2_journal_commit_transaction(journal_t *journal)
 		   &commit_transaction->t_outstanding_credits);
 
 	trace_jbd2_commit_flushing(journal, commit_transaction);
-	stats.run.rs_flushing = jiffies;
-	stats.run.rs_locked = jbd2_time_diff(stats.run.rs_locked,
-					     stats.run.rs_flushing);
+	stats.run.rs_locked = get_us_since(&prev);
 
 	commit_transaction->t_state = T_FLUSH;
 	journal->j_committing_transaction = commit_transaction;
@@ -562,9 +564,7 @@ void jbd2_journal_commit_transaction(journal_t *journal)
 	write_unlock(&journal->j_state_lock);
 
 	trace_jbd2_commit_logging(journal, commit_transaction);
-	stats.run.rs_logging = jiffies;
-	stats.run.rs_flushing = jbd2_time_diff(stats.run.rs_flushing,
-					       stats.run.rs_logging);
+	stats.run.rs_flushing = get_us_since(&prev);
 	stats.run.rs_blocks = commit_transaction->t_nr_buffers;
 	stats.run.rs_blocks_logged = 0;
 
@@ -806,6 +806,7 @@ void jbd2_journal_commit_transaction(journal_t *journal)
 	*/
 
 	jbd2_debug(3, "JBD2: commit phase 3\n");
+	stats.run.rs_logging_1 = get_us_since(&prev);
 
 	while (!list_empty(&io_bufs)) {
 		struct buffer_head *bh = list_entry(io_bufs.prev,
@@ -872,6 +873,8 @@ void jbd2_journal_commit_transaction(journal_t *journal)
 	if (err)
 		jbd2_journal_abort(journal, err);
 
+	stats.run.rs_logging_2 = get_us_since(&prev);
+
 	jbd2_debug(3, "JBD2: commit phase 5\n");
 	write_lock(&journal->j_state_lock);
 	J_ASSERT(commit_transaction->t_state == T_COMMIT_DFLUSH);
@@ -917,6 +920,8 @@ void jbd2_journal_commit_transaction(journal_t *journal)
 	J_ASSERT(commit_transaction->t_buffers == NULL);
 	J_ASSERT(commit_transaction->t_checkpoint_list == NULL);
 	J_ASSERT(commit_transaction->t_shadow_list == NULL);
+	stats.run.rs_logging_3 = get_us_since(&prev);
+
 
 restart_loop:
 	/*
@@ -1093,8 +1098,7 @@ void jbd2_journal_commit_transaction(journal_t *journal)
 	J_ASSERT(commit_transaction->t_state == T_COMMIT_JFLUSH);
 
 	commit_transaction->t_start = jiffies;
-	stats.run.rs_logging = jbd2_time_diff(stats.run.rs_logging,
-					      commit_transaction->t_start);
+	stats.run.rs_logging_4 = get_us_since(&prev);
 
 	/*
 	 * File the transaction statistics
@@ -1145,6 +1149,8 @@ void jbd2_journal_commit_transaction(journal_t *journal)
 	}
 	spin_unlock(&journal->j_list_lock);
 	write_unlock(&journal->j_state_lock);
+	// if (jbd2_has_feature_fast_commit(journal))
+	// 	commit_done = ktime_get();
 	wake_up(&journal->j_wait_done_commit);
 	wake_up(&journal->j_fc_wait);
 
@@ -1159,7 +1165,10 @@ void jbd2_journal_commit_transaction(journal_t *journal)
 	journal->j_stats.run.rs_running += stats.run.rs_running;
 	journal->j_stats.run.rs_locked += stats.run.rs_locked;
 	journal->j_stats.run.rs_flushing += stats.run.rs_flushing;
-	journal->j_stats.run.rs_logging += stats.run.rs_logging;
+	journal->j_stats.run.rs_logging_1 += stats.run.rs_logging_1;
+	journal->j_stats.run.rs_logging_2 += stats.run.rs_logging_2;
+	journal->j_stats.run.rs_logging_3 += stats.run.rs_logging_3;
+	journal->j_stats.run.rs_logging_4 += stats.run.rs_logging_4;
 	journal->j_stats.run.rs_handle_count += stats.run.rs_handle_count;
 	journal->j_stats.run.rs_blocks += stats.run.rs_blocks;
 	journal->j_stats.run.rs_blocks_logged += stats.run.rs_blocks_logged;
diff --git a/fs/jbd2/journal.c b/fs/jbd2/journal.c
index f243552eadad..03f0654da0c0 100644
--- a/fs/jbd2/journal.c
+++ b/fs/jbd2/journal.c
@@ -97,6 +97,9 @@ EXPORT_SYMBOL(jbd2_inode_cache);
 
 static int jbd2_journal_create_slab(size_t slab_size);
 
+// extern ktime_t jthread_wakes_up;
+// extern ktime_t commit_done;
+
 #ifdef CONFIG_JBD2_DEBUG
 void __jbd2_debug(int level, const char *file, const char *func,
 		  unsigned int line, const char *fmt, ...)
@@ -239,6 +242,8 @@ static int kjournald2(void *arg)
 		}
 		finish_wait(&journal->j_wait_commit, &wait);
 	}
+	// if (jbd2_has_feature_fast_commit(journal))
+	// 	jthread_wakes_up = ktime_get();
 
 	jbd2_debug(1, "kjournald2 wakes\n");
 
@@ -488,7 +493,7 @@ static int __jbd2_log_start_commit(journal_t *journal, tid_t target)
 		jbd2_debug(1, "JBD2: requesting commit %u/%u\n",
 			  journal->j_commit_request,
 			  journal->j_commit_sequence);
-		journal->j_running_transaction->t_requested = jiffies;
+		journal->j_running_transaction->t_requested = ktime_get();
 		wake_up(&journal->j_wait_commit);
 		return 1;
 	} else if (!tid_geq(journal->j_commit_request, target))
@@ -810,7 +815,9 @@ EXPORT_SYMBOL(jbd2_transaction_committed);
  */
 int jbd2_complete_transaction(journal_t *journal, tid_t tid)
 {
-	int	need_to_wait = 1;
+	int	need_to_wait = 1, ret, requested = 0;
+	ktime_t prev;//, requested_time;
+	prev = ktime_get();
 
 	read_lock(&journal->j_state_lock);
 	if (journal->j_running_transaction &&
@@ -818,17 +825,30 @@ int jbd2_complete_transaction(journal_t *journal, tid_t tid)
 		if (journal->j_commit_request != tid) {
 			/* transaction not yet started, so request it */
 			read_unlock(&journal->j_state_lock);
+			// requested_time = ktime_get();
 			jbd2_log_start_commit(journal, tid);
+			requested = 1;
 			goto wait_commit;
 		}
 	} else if (!(journal->j_committing_transaction &&
 		     journal->j_committing_transaction->t_tid == tid))
 		need_to_wait = 0;
 	read_unlock(&journal->j_state_lock);
-	if (!need_to_wait)
+	if (!need_to_wait) {
+		journal->j_complete_tx_time += get_us_since(&prev);
 		return 0;
+	}
 wait_commit:
-	return jbd2_log_wait_commit(journal, tid);
+	ret = jbd2_log_wait_commit(journal, tid);
+	// if (requested && jbd2_has_feature_fast_commit(journal)) {
+	// 	printk(KERN_ERR "fsync -> journal: %lld\n",
+	// 		ktime_to_ns(ktime_sub(jthread_wakes_up, requested_time)));
+	// 	printk(KERN_ERR "journal -> fsync: %lld\n",
+	// 		ktime_to_ns(ktime_sub(ktime_get(), commit_done)));
+	// }
+	if (requested)
+		journal->j_complete_tx_time += get_us_since(&prev);
+	return ret;
 }
 EXPORT_SYMBOL(jbd2_complete_transaction);
 
@@ -1165,20 +1185,25 @@ static int jbd2_seq_info_show(struct seq_file *seq, void *v)
 		   s->journal->j_max_transaction_buffers);
 	if (s->stats->ts_tid == 0)
 		return 0;
-	seq_printf(seq, "average: \n  %ums waiting for transaction\n",
-	    jiffies_to_msecs(s->stats->run.rs_wait / s->stats->ts_tid));
-	seq_printf(seq, "  %ums request delay\n",
+	seq_printf(seq, "total: \n  %lums waiting for transaction\n",
+	    s->stats->run.rs_wait / s->stats->ts_tid);
+	seq_printf(seq, "  %luus request delay\n",
 	    (s->stats->ts_requested == 0) ? 0 :
-	    jiffies_to_msecs(s->stats->run.rs_request_delay /
-			     s->stats->ts_requested));
-	seq_printf(seq, "  %ums running transaction\n",
-	    jiffies_to_msecs(s->stats->run.rs_running / s->stats->ts_tid));
-	seq_printf(seq, "  %ums transaction was being locked\n",
-	    jiffies_to_msecs(s->stats->run.rs_locked / s->stats->ts_tid));
-	seq_printf(seq, "  %ums flushing data (in ordered mode)\n",
-	    jiffies_to_msecs(s->stats->run.rs_flushing / s->stats->ts_tid));
-	seq_printf(seq, "  %ums logging transaction\n",
-	    jiffies_to_msecs(s->stats->run.rs_logging / s->stats->ts_tid));
+	    s->stats->run.rs_request_delay);
+	seq_printf(seq, "  %luus running transaction\n",
+	    s->stats->run.rs_running);
+	seq_printf(seq, "  %luus transaction was being locked\n",
+	    s->stats->run.rs_locked );
+	seq_printf(seq, "  %luus flushing data (in ordered mode)\n",
+	    s->stats->run.rs_flushing);
+	seq_printf(seq, "  %luus ph1 logging transaction\n",
+	    s->stats->run.rs_logging_1);
+	seq_printf(seq, "  %luus ph2 logging transaction\n",
+	    s->stats->run.rs_logging_2);
+	seq_printf(seq, "  %luus ph3 logging transaction\n",
+	    s->stats->run.rs_logging_3);
+	seq_printf(seq, "  %luus ph4 logging transaction\n",
+	    s->stats->run.rs_logging_4);
 	seq_printf(seq, "  %lluus average transaction commit time\n",
 		   div_u64(s->journal->j_average_commit_time, 1000));
 	seq_printf(seq, "  %lu handles per transaction\n",
@@ -1187,6 +1212,8 @@ static int jbd2_seq_info_show(struct seq_file *seq, void *v)
 	    s->stats->run.rs_blocks / s->stats->ts_tid);
 	seq_printf(seq, "  %lu logged blocks per transaction\n",
 	    s->stats->run.rs_blocks_logged / s->stats->ts_tid);
+	seq_printf(seq, "  %lld actual time\n", s->journal->j_complete_tx_time);
+
 	return 0;
 }
 
diff --git a/fs/jbd2/transaction.c b/fs/jbd2/transaction.c
index cb0b8d6fc0c6..f49c6dcd5596 100644
--- a/fs/jbd2/transaction.c
+++ b/fs/jbd2/transaction.c
@@ -904,6 +904,28 @@ void jbd2_journal_lock_updates(journal_t *journal)
 	mutex_lock(&journal->j_barrier);
 }
 
+
+void jbd2_journal_lock_updates_no_rsv(journal_t *journal)
+{
+	jbd2_might_wait_for_commit(journal);
+
+	write_lock(&journal->j_state_lock);
+	++journal->j_barrier_count;
+
+	/* Wait until there are no running t_updates */
+	jbd2_journal_wait_updates(journal);
+
+	write_unlock(&journal->j_state_lock);
+
+	/*
+	 * We have now established a barrier against other normal updates, but
+	 * we also need to barrier against other jbd2_journal_lock_updates() calls
+	 * to make sure that we serialise special journal-locked operations
+	 * too.
+	 */
+	mutex_lock(&journal->j_barrier);
+}
+
 /**
  * jbd2_journal_unlock_updates () - release barrier
  * @journal:  Journal to release the barrier on.
diff --git a/include/linux/jbd2.h b/include/linux/jbd2.h
index 971f3e826e15..5c7af4a73d43 100644
--- a/include/linux/jbd2.h
+++ b/include/linux/jbd2.h
@@ -643,7 +643,7 @@ struct transaction_s
 	/*
 	 * When commit was requested [j_state_lock]
 	 */
-	unsigned long		t_requested;
+	u64		t_requested;
 
 	/*
 	 * Checkpointing stats [j_list_lock]
@@ -714,7 +714,10 @@ struct transaction_run_stats_s {
 	unsigned long		rs_running;
 	unsigned long		rs_locked;
 	unsigned long		rs_flushing;
-	unsigned long		rs_logging;
+	unsigned long		rs_logging_1;
+	unsigned long		rs_logging_2;
+	unsigned long		rs_logging_3;
+	unsigned long		rs_logging_4;
 
 	__u32			rs_handle_count;
 	__u32			rs_blocks;
@@ -736,6 +739,16 @@ jbd2_time_diff(unsigned long start, unsigned long end)
 	return end + (MAX_JIFFY_OFFSET - start);
 }
 
+static inline u64 get_us_since(ktime_t *prev)
+{
+	ktime_t now;
+	u64 diff;
+	now = ktime_get();
+	diff = ktime_to_us(ktime_sub(now, *prev));
+	*prev = now;
+	return diff;
+}
+
 #define JBD2_NR_BATCH	64
 
 enum passtype {PASS_SCAN, PASS_REVOKE, PASS_REPLAY};
@@ -1293,6 +1306,8 @@ struct journal_s
 	 * VFS bmap function.
 	 */
 	int (*j_bmap)(struct journal_s *journal, sector_t *block);
+	u64 j_complete_tx_time;
+	u64 j_total_tx;
 };
 
 #define jbd2_might_wait_for_commit(j) \
@@ -1529,6 +1544,7 @@ bool jbd2_journal_try_to_free_buffers(journal_t *journal, struct folio *folio);
 extern int	 jbd2_journal_stop(handle_t *);
 extern int	 jbd2_journal_flush(journal_t *journal, unsigned int flags);
 extern void	 jbd2_journal_lock_updates (journal_t *);
+void jbd2_journal_lock_updates_no_rsv(journal_t *journal);
 extern void	 jbd2_journal_unlock_updates (journal_t *);
 
 void jbd2_journal_wait_updates(journal_t *);
diff --git a/include/trace/events/jbd2.h b/include/trace/events/jbd2.h
index 5646ae15a957..aa2ba3a12c84 100644
--- a/include/trace/events/jbd2.h
+++ b/include/trace/events/jbd2.h
@@ -273,7 +273,7 @@ TRACE_EVENT(jbd2_run_stats,
 		__entry->running	= stats->rs_running;
 		__entry->locked		= stats->rs_locked;
 		__entry->flushing	= stats->rs_flushing;
-		__entry->logging	= stats->rs_logging;
+		__entry->logging	= stats->rs_logging_1;
 		__entry->handle_count	= stats->rs_handle_count;
 		__entry->blocks		= stats->rs_blocks;
 		__entry->blocks_logged	= stats->rs_blocks_logged;
-- 
2.43.0.429.g432eaa2c6b-goog

